{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 19:35:23.823228: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la red neuronal convulucional es una red enuronal con unas capas y neuronas predeterminadas y se usa sobre todo para tratar imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r1/hd_91nzn1yb8kh1vq1c7gt2w0000gn/T/ipykernel_4077/3096108358.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential() #todas las redes neuronales son secuencial, todas comienza con este tipo\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28))) #capa de entrada, añadimos una layer de estilo flatten. el 28x28 son los input porque son los pixeles\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu')) #capa oculta\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax')) #capa de salida, pones tantas neuronas como grupos a clasificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.reshaping.flatten.Flatten object at 0x14af42e50>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00263695, -0.04666627,  0.07183836, ..., -0.00341597,\n",
       "        -0.0105683 ,  0.03797045],\n",
       "       [-0.05174806,  0.06435077, -0.01683674, ...,  0.04660314,\n",
       "        -0.01421911,  0.05380225],\n",
       "       [-0.0010645 , -0.05638417,  0.00470252, ..., -0.03035436,\n",
       "         0.05526266, -0.01098748],\n",
       "       ...,\n",
       "       [ 0.0417054 , -0.02520613, -0.05357894, ...,  0.03111812,\n",
       "         0.0017412 , -0.01989841],\n",
       "       [-0.02295094, -0.0617586 , -0.0186105 , ..., -0.0615017 ,\n",
       "        -0.07122992,  0.02824512],\n",
       "       [ 0.06151454, -0.07436188, -0.0239237 , ...,  0.05233708,\n",
       "        -0.04393759,  0.06685658]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(), #el optimizador\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(), #función de pérdida, esta justo se usa para multiclases\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()] #métricas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary() #nos devuelve las capas de la red neuronal con su info. Los parámetros es el número de neurona por la cantidad de pesos, la segunda capa oculta es porque son 300*100+100 (porque cada una pueden ser ella solas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 3s 5ms/step - loss: 1.2969 - accuracy: 0.6871 - val_loss: 0.6223 - val_accuracy: 0.8577\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.5314 - accuracy: 0.8647 - val_loss: 0.4045 - val_accuracy: 0.8950\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.4071 - accuracy: 0.8886 - val_loss: 0.3421 - val_accuracy: 0.9071\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.3561 - accuracy: 0.8998 - val_loss: 0.3089 - val_accuracy: 0.9138\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3255 - accuracy: 0.9074 - val_loss: 0.2879 - val_accuracy: 0.9179\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3033 - accuracy: 0.9131 - val_loss: 0.2713 - val_accuracy: 0.9221\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2855 - accuracy: 0.9185 - val_loss: 0.2587 - val_accuracy: 0.9255\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2709 - accuracy: 0.9220 - val_loss: 0.2472 - val_accuracy: 0.9286\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2581 - accuracy: 0.9261 - val_loss: 0.2375 - val_accuracy: 0.9313\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2466 - accuracy: 0.9297 - val_loss: 0.2285 - val_accuracy: 0.9347\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.2362 - accuracy: 0.9323 - val_loss: 0.2207 - val_accuracy: 0.9368\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.2268 - accuracy: 0.9346 - val_loss: 0.2125 - val_accuracy: 0.9404\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2184 - accuracy: 0.9379 - val_loss: 0.2051 - val_accuracy: 0.9425\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2100 - accuracy: 0.9403 - val_loss: 0.1990 - val_accuracy: 0.9449\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2029 - accuracy: 0.9425 - val_loss: 0.1934 - val_accuracy: 0.9460\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.1961 - accuracy: 0.9445 - val_loss: 0.1877 - val_accuracy: 0.9482\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.1896 - accuracy: 0.9463 - val_loss: 0.1817 - val_accuracy: 0.9502\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1835 - accuracy: 0.9477 - val_loss: 0.1773 - val_accuracy: 0.9519\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.1777 - accuracy: 0.9497 - val_loss: 0.1726 - val_accuracy: 0.9527\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1725 - accuracy: 0.9510 - val_loss: 0.1679 - val_accuracy: 0.9530\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.1675 - accuracy: 0.9523 - val_loss: 0.1665 - val_accuracy: 0.9549\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1626 - accuracy: 0.9537 - val_loss: 0.1614 - val_accuracy: 0.9554\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.1579 - accuracy: 0.9548 - val_loss: 0.1576 - val_accuracy: 0.9562\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.1537 - accuracy: 0.9561 - val_loss: 0.1555 - val_accuracy: 0.9564\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1496 - accuracy: 0.9574 - val_loss: 0.1509 - val_accuracy: 0.9584\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1455 - accuracy: 0.9575 - val_loss: 0.1477 - val_accuracy: 0.9586\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1418 - accuracy: 0.9591 - val_loss: 0.1447 - val_accuracy: 0.9603\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1381 - accuracy: 0.9604 - val_loss: 0.1430 - val_accuracy: 0.9609\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1346 - accuracy: 0.9612 - val_loss: 0.1401 - val_accuracy: 0.9610\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1315 - accuracy: 0.9626 - val_loss: 0.1383 - val_accuracy: 0.9616\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1282 - accuracy: 0.9632 - val_loss: 0.1363 - val_accuracy: 0.9639\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1251 - accuracy: 0.9645 - val_loss: 0.1331 - val_accuracy: 0.9624\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1221 - accuracy: 0.9653 - val_loss: 0.1311 - val_accuracy: 0.9627\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1195 - accuracy: 0.9663 - val_loss: 0.1288 - val_accuracy: 0.9645\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1167 - accuracy: 0.9671 - val_loss: 0.1273 - val_accuracy: 0.9651\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1139 - accuracy: 0.9675 - val_loss: 0.1258 - val_accuracy: 0.9650\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1114 - accuracy: 0.9689 - val_loss: 0.1236 - val_accuracy: 0.9660\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1088 - accuracy: 0.9692 - val_loss: 0.1216 - val_accuracy: 0.9663\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1066 - accuracy: 0.9702 - val_loss: 0.1202 - val_accuracy: 0.9670\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1044 - accuracy: 0.9712 - val_loss: 0.1181 - val_accuracy: 0.9670\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1022 - accuracy: 0.9719 - val_loss: 0.1181 - val_accuracy: 0.9674\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1000 - accuracy: 0.9722 - val_loss: 0.1155 - val_accuracy: 0.9685\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0977 - accuracy: 0.9731 - val_loss: 0.1145 - val_accuracy: 0.9686\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0959 - accuracy: 0.9735 - val_loss: 0.1132 - val_accuracy: 0.9679\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.0939 - accuracy: 0.9743 - val_loss: 0.1128 - val_accuracy: 0.9689\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0921 - accuracy: 0.9746 - val_loss: 0.1108 - val_accuracy: 0.9686\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0904 - accuracy: 0.9749 - val_loss: 0.1094 - val_accuracy: 0.9692\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0884 - accuracy: 0.9758 - val_loss: 0.1082 - val_accuracy: 0.9694\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0868 - accuracy: 0.9764 - val_loss: 0.1080 - val_accuracy: 0.9696\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0851 - accuracy: 0.9769 - val_loss: 0.1069 - val_accuracy: 0.9710\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ") #Lo guardamos en la variabe para poder graficarlo\n",
    "\n",
    "#Accyracy da la predicción \n",
    "#Val accyraccy da la predicción de un nuevo dato que nunca ha visto, asi que con estos datos da que tal va y si hay overfitting o no\n",
    "#comparando el accuracy con el val_accuracy te dice si bien, overfitting o underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0592 - accuracy: 0.9847 - val_loss: 0.0904 - val_accuracy: 0.9745\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 4ms/step - loss: 0.0575 - accuracy: 0.9848 - val_loss: 0.0895 - val_accuracy: 0.9748\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0557 - accuracy: 0.9852 - val_loss: 0.0893 - val_accuracy: 0.9749\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0538 - accuracy: 0.9863 - val_loss: 0.0900 - val_accuracy: 0.9744\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0522 - accuracy: 0.9866 - val_loss: 0.0876 - val_accuracy: 0.9754\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0506 - accuracy: 0.9868 - val_loss: 0.0864 - val_accuracy: 0.9757\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0489 - accuracy: 0.9877 - val_loss: 0.0883 - val_accuracy: 0.9750\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0473 - accuracy: 0.9885 - val_loss: 0.0872 - val_accuracy: 0.9745\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0460 - accuracy: 0.9883 - val_loss: 0.0865 - val_accuracy: 0.9760\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0446 - accuracy: 0.9888 - val_loss: 0.0847 - val_accuracy: 0.9757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14c82ccd0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64, #es bueno usar los batch como los bits, 2,4,8,16,62... etc\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 50, 'steps': 391}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [1.2968944311141968,\n",
       "  0.5314479470252991,\n",
       "  0.407123327255249,\n",
       "  0.35610684752464294,\n",
       "  0.3254680931568146,\n",
       "  0.30329546332359314,\n",
       "  0.28554412722587585,\n",
       "  0.27092334628105164,\n",
       "  0.25808629393577576,\n",
       "  0.24658800661563873,\n",
       "  0.23618751764297485,\n",
       "  0.22681133449077606,\n",
       "  0.2183787077665329,\n",
       "  0.2099563628435135,\n",
       "  0.2028503119945526,\n",
       "  0.19611695408821106,\n",
       "  0.18957702815532684,\n",
       "  0.18348997831344604,\n",
       "  0.17773759365081787,\n",
       "  0.17250457406044006,\n",
       "  0.1675267517566681,\n",
       "  0.1626276820898056,\n",
       "  0.15794526040554047,\n",
       "  0.15366262197494507,\n",
       "  0.1495838165283203,\n",
       "  0.14554588496685028,\n",
       "  0.14176851511001587,\n",
       "  0.1381361335515976,\n",
       "  0.1346384882926941,\n",
       "  0.13145491480827332,\n",
       "  0.12816697359085083,\n",
       "  0.12510313093662262,\n",
       "  0.12207332998514175,\n",
       "  0.11951063573360443,\n",
       "  0.11667876690626144,\n",
       "  0.113896943628788,\n",
       "  0.11136926710605621,\n",
       "  0.10882251709699631,\n",
       "  0.10662498325109482,\n",
       "  0.10436338186264038,\n",
       "  0.10216706246137619,\n",
       "  0.09995435178279877,\n",
       "  0.09773620963096619,\n",
       "  0.0959010049700737,\n",
       "  0.0938882976770401,\n",
       "  0.09214042872190475,\n",
       "  0.0903763398528099,\n",
       "  0.08844657242298126,\n",
       "  0.08682135492563248,\n",
       "  0.0851057693362236],\n",
       " 'accuracy': [0.6871200203895569,\n",
       "  0.8646600246429443,\n",
       "  0.8886200189590454,\n",
       "  0.8997600078582764,\n",
       "  0.9073799848556519,\n",
       "  0.9131199717521667,\n",
       "  0.9184600114822388,\n",
       "  0.921999990940094,\n",
       "  0.9261199831962585,\n",
       "  0.9297199845314026,\n",
       "  0.9323400259017944,\n",
       "  0.9346399903297424,\n",
       "  0.9379000067710876,\n",
       "  0.940280020236969,\n",
       "  0.9425399899482727,\n",
       "  0.9444800019264221,\n",
       "  0.9462599754333496,\n",
       "  0.9476799964904785,\n",
       "  0.9496600031852722,\n",
       "  0.9510400295257568,\n",
       "  0.9522600173950195,\n",
       "  0.9537000060081482,\n",
       "  0.9548199772834778,\n",
       "  0.9561399817466736,\n",
       "  0.9574199914932251,\n",
       "  0.9574599862098694,\n",
       "  0.959119975566864,\n",
       "  0.9604200124740601,\n",
       "  0.9612399935722351,\n",
       "  0.9625599980354309,\n",
       "  0.9632200002670288,\n",
       "  0.964460015296936,\n",
       "  0.9652600288391113,\n",
       "  0.9662600159645081,\n",
       "  0.9671199917793274,\n",
       "  0.9675400257110596,\n",
       "  0.9688799977302551,\n",
       "  0.9692400097846985,\n",
       "  0.9702000021934509,\n",
       "  0.9711800217628479,\n",
       "  0.9719200134277344,\n",
       "  0.9721599817276001,\n",
       "  0.9731000065803528,\n",
       "  0.9735199809074402,\n",
       "  0.9743000268936157,\n",
       "  0.97461998462677,\n",
       "  0.9749000072479248,\n",
       "  0.975820004940033,\n",
       "  0.976360023021698,\n",
       "  0.9769399762153625],\n",
       " 'val_loss': [0.6223294734954834,\n",
       "  0.40450963377952576,\n",
       "  0.3420726954936981,\n",
       "  0.30889278650283813,\n",
       "  0.28789862990379333,\n",
       "  0.2712758183479309,\n",
       "  0.25867366790771484,\n",
       "  0.24723535776138306,\n",
       "  0.23750098049640656,\n",
       "  0.22851431369781494,\n",
       "  0.22072988748550415,\n",
       "  0.2124888002872467,\n",
       "  0.20512312650680542,\n",
       "  0.19897229969501495,\n",
       "  0.1934155821800232,\n",
       "  0.18765318393707275,\n",
       "  0.18167878687381744,\n",
       "  0.17730772495269775,\n",
       "  0.1725919246673584,\n",
       "  0.1679372787475586,\n",
       "  0.16651684045791626,\n",
       "  0.16138610243797302,\n",
       "  0.15758384764194489,\n",
       "  0.1554955542087555,\n",
       "  0.15094247460365295,\n",
       "  0.14772632718086243,\n",
       "  0.14466635882854462,\n",
       "  0.14301486313343048,\n",
       "  0.14009305834770203,\n",
       "  0.1382506936788559,\n",
       "  0.13634653389453888,\n",
       "  0.13310645520687103,\n",
       "  0.13114769756793976,\n",
       "  0.12875555455684662,\n",
       "  0.12732301652431488,\n",
       "  0.12583649158477783,\n",
       "  0.12359640747308731,\n",
       "  0.1216464713215828,\n",
       "  0.12024029344320297,\n",
       "  0.11807951331138611,\n",
       "  0.11809349060058594,\n",
       "  0.1155318096280098,\n",
       "  0.11452489346265793,\n",
       "  0.11323908716440201,\n",
       "  0.11277256160974503,\n",
       "  0.11083266884088516,\n",
       "  0.10938956588506699,\n",
       "  0.10823242366313934,\n",
       "  0.10798283666372299,\n",
       "  0.10686282068490982],\n",
       " 'val_accuracy': [0.857699990272522,\n",
       "  0.8949999809265137,\n",
       "  0.9071000218391418,\n",
       "  0.9138000011444092,\n",
       "  0.917900025844574,\n",
       "  0.9221000075340271,\n",
       "  0.9254999756813049,\n",
       "  0.928600013256073,\n",
       "  0.9312999844551086,\n",
       "  0.9347000122070312,\n",
       "  0.9368000030517578,\n",
       "  0.9404000043869019,\n",
       "  0.9424999952316284,\n",
       "  0.9448999762535095,\n",
       "  0.9459999799728394,\n",
       "  0.948199987411499,\n",
       "  0.9502000212669373,\n",
       "  0.9519000053405762,\n",
       "  0.9527000188827515,\n",
       "  0.953000009059906,\n",
       "  0.9549000263214111,\n",
       "  0.9553999900817871,\n",
       "  0.9562000036239624,\n",
       "  0.9563999772071838,\n",
       "  0.9584000110626221,\n",
       "  0.9585999846458435,\n",
       "  0.9603000283241272,\n",
       "  0.9609000086784363,\n",
       "  0.9610000252723694,\n",
       "  0.9616000056266785,\n",
       "  0.9639000296592712,\n",
       "  0.9624000191688538,\n",
       "  0.9627000093460083,\n",
       "  0.9645000100135803,\n",
       "  0.9650999903678894,\n",
       "  0.9649999737739563,\n",
       "  0.9660000205039978,\n",
       "  0.9663000106811523,\n",
       "  0.9670000076293945,\n",
       "  0.9670000076293945,\n",
       "  0.9674000144004822,\n",
       "  0.968500018119812,\n",
       "  0.9685999751091003,\n",
       "  0.9678999781608582,\n",
       "  0.9689000248908997,\n",
       "  0.9685999751091003,\n",
       "  0.9692000150680542,\n",
       "  0.9693999886512756,\n",
       "  0.9696000218391418,\n",
       "  0.9710000157356262]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.2968944311141968,\n",
       "  0.5314479470252991,\n",
       "  0.407123327255249,\n",
       "  0.35610684752464294,\n",
       "  0.3254680931568146,\n",
       "  0.30329546332359314,\n",
       "  0.28554412722587585,\n",
       "  0.27092334628105164,\n",
       "  0.25808629393577576,\n",
       "  0.24658800661563873,\n",
       "  0.23618751764297485,\n",
       "  0.22681133449077606,\n",
       "  0.2183787077665329,\n",
       "  0.2099563628435135,\n",
       "  0.2028503119945526,\n",
       "  0.19611695408821106,\n",
       "  0.18957702815532684,\n",
       "  0.18348997831344604,\n",
       "  0.17773759365081787,\n",
       "  0.17250457406044006,\n",
       "  0.1675267517566681,\n",
       "  0.1626276820898056,\n",
       "  0.15794526040554047,\n",
       "  0.15366262197494507,\n",
       "  0.1495838165283203,\n",
       "  0.14554588496685028,\n",
       "  0.14176851511001587,\n",
       "  0.1381361335515976,\n",
       "  0.1346384882926941,\n",
       "  0.13145491480827332,\n",
       "  0.12816697359085083,\n",
       "  0.12510313093662262,\n",
       "  0.12207332998514175,\n",
       "  0.11951063573360443,\n",
       "  0.11667876690626144,\n",
       "  0.113896943628788,\n",
       "  0.11136926710605621,\n",
       "  0.10882251709699631,\n",
       "  0.10662498325109482,\n",
       "  0.10436338186264038,\n",
       "  0.10216706246137619,\n",
       "  0.09995435178279877,\n",
       "  0.09773620963096619,\n",
       "  0.0959010049700737,\n",
       "  0.0938882976770401,\n",
       "  0.09214042872190475,\n",
       "  0.0903763398528099,\n",
       "  0.08844657242298126,\n",
       "  0.08682135492563248,\n",
       "  0.0851057693362236],\n",
       " 'accuracy': [0.6871200203895569,\n",
       "  0.8646600246429443,\n",
       "  0.8886200189590454,\n",
       "  0.8997600078582764,\n",
       "  0.9073799848556519,\n",
       "  0.9131199717521667,\n",
       "  0.9184600114822388,\n",
       "  0.921999990940094,\n",
       "  0.9261199831962585,\n",
       "  0.9297199845314026,\n",
       "  0.9323400259017944,\n",
       "  0.9346399903297424,\n",
       "  0.9379000067710876,\n",
       "  0.940280020236969,\n",
       "  0.9425399899482727,\n",
       "  0.9444800019264221,\n",
       "  0.9462599754333496,\n",
       "  0.9476799964904785,\n",
       "  0.9496600031852722,\n",
       "  0.9510400295257568,\n",
       "  0.9522600173950195,\n",
       "  0.9537000060081482,\n",
       "  0.9548199772834778,\n",
       "  0.9561399817466736,\n",
       "  0.9574199914932251,\n",
       "  0.9574599862098694,\n",
       "  0.959119975566864,\n",
       "  0.9604200124740601,\n",
       "  0.9612399935722351,\n",
       "  0.9625599980354309,\n",
       "  0.9632200002670288,\n",
       "  0.964460015296936,\n",
       "  0.9652600288391113,\n",
       "  0.9662600159645081,\n",
       "  0.9671199917793274,\n",
       "  0.9675400257110596,\n",
       "  0.9688799977302551,\n",
       "  0.9692400097846985,\n",
       "  0.9702000021934509,\n",
       "  0.9711800217628479,\n",
       "  0.9719200134277344,\n",
       "  0.9721599817276001,\n",
       "  0.9731000065803528,\n",
       "  0.9735199809074402,\n",
       "  0.9743000268936157,\n",
       "  0.97461998462677,\n",
       "  0.9749000072479248,\n",
       "  0.975820004940033,\n",
       "  0.976360023021698,\n",
       "  0.9769399762153625],\n",
       " 'val_loss': [0.6223294734954834,\n",
       "  0.40450963377952576,\n",
       "  0.3420726954936981,\n",
       "  0.30889278650283813,\n",
       "  0.28789862990379333,\n",
       "  0.2712758183479309,\n",
       "  0.25867366790771484,\n",
       "  0.24723535776138306,\n",
       "  0.23750098049640656,\n",
       "  0.22851431369781494,\n",
       "  0.22072988748550415,\n",
       "  0.2124888002872467,\n",
       "  0.20512312650680542,\n",
       "  0.19897229969501495,\n",
       "  0.1934155821800232,\n",
       "  0.18765318393707275,\n",
       "  0.18167878687381744,\n",
       "  0.17730772495269775,\n",
       "  0.1725919246673584,\n",
       "  0.1679372787475586,\n",
       "  0.16651684045791626,\n",
       "  0.16138610243797302,\n",
       "  0.15758384764194489,\n",
       "  0.1554955542087555,\n",
       "  0.15094247460365295,\n",
       "  0.14772632718086243,\n",
       "  0.14466635882854462,\n",
       "  0.14301486313343048,\n",
       "  0.14009305834770203,\n",
       "  0.1382506936788559,\n",
       "  0.13634653389453888,\n",
       "  0.13310645520687103,\n",
       "  0.13114769756793976,\n",
       "  0.12875555455684662,\n",
       "  0.12732301652431488,\n",
       "  0.12583649158477783,\n",
       "  0.12359640747308731,\n",
       "  0.1216464713215828,\n",
       "  0.12024029344320297,\n",
       "  0.11807951331138611,\n",
       "  0.11809349060058594,\n",
       "  0.1155318096280098,\n",
       "  0.11452489346265793,\n",
       "  0.11323908716440201,\n",
       "  0.11277256160974503,\n",
       "  0.11083266884088516,\n",
       "  0.10938956588506699,\n",
       "  0.10823242366313934,\n",
       "  0.10798283666372299,\n",
       "  0.10686282068490982],\n",
       " 'val_accuracy': [0.857699990272522,\n",
       "  0.8949999809265137,\n",
       "  0.9071000218391418,\n",
       "  0.9138000011444092,\n",
       "  0.917900025844574,\n",
       "  0.9221000075340271,\n",
       "  0.9254999756813049,\n",
       "  0.928600013256073,\n",
       "  0.9312999844551086,\n",
       "  0.9347000122070312,\n",
       "  0.9368000030517578,\n",
       "  0.9404000043869019,\n",
       "  0.9424999952316284,\n",
       "  0.9448999762535095,\n",
       "  0.9459999799728394,\n",
       "  0.948199987411499,\n",
       "  0.9502000212669373,\n",
       "  0.9519000053405762,\n",
       "  0.9527000188827515,\n",
       "  0.953000009059906,\n",
       "  0.9549000263214111,\n",
       "  0.9553999900817871,\n",
       "  0.9562000036239624,\n",
       "  0.9563999772071838,\n",
       "  0.9584000110626221,\n",
       "  0.9585999846458435,\n",
       "  0.9603000283241272,\n",
       "  0.9609000086784363,\n",
       "  0.9610000252723694,\n",
       "  0.9616000056266785,\n",
       "  0.9639000296592712,\n",
       "  0.9624000191688538,\n",
       "  0.9627000093460083,\n",
       "  0.9645000100135803,\n",
       "  0.9650999903678894,\n",
       "  0.9649999737739563,\n",
       "  0.9660000205039978,\n",
       "  0.9663000106811523,\n",
       "  0.9670000076293945,\n",
       "  0.9670000076293945,\n",
       "  0.9674000144004822,\n",
       "  0.968500018119812,\n",
       "  0.9685999751091003,\n",
       "  0.9678999781608582,\n",
       "  0.9689000248908997,\n",
       "  0.9685999751091003,\n",
       "  0.9692000150680542,\n",
       "  0.9693999886512756,\n",
       "  0.9696000218391418,\n",
       "  0.9710000157356262]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.296894</td>\n",
       "      <td>0.68712</td>\n",
       "      <td>0.622329</td>\n",
       "      <td>0.8577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.531448</td>\n",
       "      <td>0.86466</td>\n",
       "      <td>0.404510</td>\n",
       "      <td>0.8950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.407123</td>\n",
       "      <td>0.88862</td>\n",
       "      <td>0.342073</td>\n",
       "      <td>0.9071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.356107</td>\n",
       "      <td>0.89976</td>\n",
       "      <td>0.308893</td>\n",
       "      <td>0.9138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.325468</td>\n",
       "      <td>0.90738</td>\n",
       "      <td>0.287899</td>\n",
       "      <td>0.9179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.303295</td>\n",
       "      <td>0.91312</td>\n",
       "      <td>0.271276</td>\n",
       "      <td>0.9221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.285544</td>\n",
       "      <td>0.91846</td>\n",
       "      <td>0.258674</td>\n",
       "      <td>0.9255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.270923</td>\n",
       "      <td>0.92200</td>\n",
       "      <td>0.247235</td>\n",
       "      <td>0.9286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.258086</td>\n",
       "      <td>0.92612</td>\n",
       "      <td>0.237501</td>\n",
       "      <td>0.9313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.246588</td>\n",
       "      <td>0.92972</td>\n",
       "      <td>0.228514</td>\n",
       "      <td>0.9347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.236188</td>\n",
       "      <td>0.93234</td>\n",
       "      <td>0.220730</td>\n",
       "      <td>0.9368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.226811</td>\n",
       "      <td>0.93464</td>\n",
       "      <td>0.212489</td>\n",
       "      <td>0.9404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.218379</td>\n",
       "      <td>0.93790</td>\n",
       "      <td>0.205123</td>\n",
       "      <td>0.9425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.209956</td>\n",
       "      <td>0.94028</td>\n",
       "      <td>0.198972</td>\n",
       "      <td>0.9449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.202850</td>\n",
       "      <td>0.94254</td>\n",
       "      <td>0.193416</td>\n",
       "      <td>0.9460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.196117</td>\n",
       "      <td>0.94448</td>\n",
       "      <td>0.187653</td>\n",
       "      <td>0.9482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.189577</td>\n",
       "      <td>0.94626</td>\n",
       "      <td>0.181679</td>\n",
       "      <td>0.9502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.183490</td>\n",
       "      <td>0.94768</td>\n",
       "      <td>0.177308</td>\n",
       "      <td>0.9519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.177738</td>\n",
       "      <td>0.94966</td>\n",
       "      <td>0.172592</td>\n",
       "      <td>0.9527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.172505</td>\n",
       "      <td>0.95104</td>\n",
       "      <td>0.167937</td>\n",
       "      <td>0.9530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.167527</td>\n",
       "      <td>0.95226</td>\n",
       "      <td>0.166517</td>\n",
       "      <td>0.9549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.162628</td>\n",
       "      <td>0.95370</td>\n",
       "      <td>0.161386</td>\n",
       "      <td>0.9554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.157945</td>\n",
       "      <td>0.95482</td>\n",
       "      <td>0.157584</td>\n",
       "      <td>0.9562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.153663</td>\n",
       "      <td>0.95614</td>\n",
       "      <td>0.155496</td>\n",
       "      <td>0.9564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.149584</td>\n",
       "      <td>0.95742</td>\n",
       "      <td>0.150942</td>\n",
       "      <td>0.9584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.145546</td>\n",
       "      <td>0.95746</td>\n",
       "      <td>0.147726</td>\n",
       "      <td>0.9586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.141769</td>\n",
       "      <td>0.95912</td>\n",
       "      <td>0.144666</td>\n",
       "      <td>0.9603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.138136</td>\n",
       "      <td>0.96042</td>\n",
       "      <td>0.143015</td>\n",
       "      <td>0.9609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.134638</td>\n",
       "      <td>0.96124</td>\n",
       "      <td>0.140093</td>\n",
       "      <td>0.9610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.131455</td>\n",
       "      <td>0.96256</td>\n",
       "      <td>0.138251</td>\n",
       "      <td>0.9616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.128167</td>\n",
       "      <td>0.96322</td>\n",
       "      <td>0.136347</td>\n",
       "      <td>0.9639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.125103</td>\n",
       "      <td>0.96446</td>\n",
       "      <td>0.133106</td>\n",
       "      <td>0.9624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.122073</td>\n",
       "      <td>0.96526</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.9627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.119511</td>\n",
       "      <td>0.96626</td>\n",
       "      <td>0.128756</td>\n",
       "      <td>0.9645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.116679</td>\n",
       "      <td>0.96712</td>\n",
       "      <td>0.127323</td>\n",
       "      <td>0.9651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.113897</td>\n",
       "      <td>0.96754</td>\n",
       "      <td>0.125836</td>\n",
       "      <td>0.9650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.111369</td>\n",
       "      <td>0.96888</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>0.9660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.108823</td>\n",
       "      <td>0.96924</td>\n",
       "      <td>0.121646</td>\n",
       "      <td>0.9663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.106625</td>\n",
       "      <td>0.97020</td>\n",
       "      <td>0.120240</td>\n",
       "      <td>0.9670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.104363</td>\n",
       "      <td>0.97118</td>\n",
       "      <td>0.118080</td>\n",
       "      <td>0.9670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.102167</td>\n",
       "      <td>0.97192</td>\n",
       "      <td>0.118093</td>\n",
       "      <td>0.9674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.099954</td>\n",
       "      <td>0.97216</td>\n",
       "      <td>0.115532</td>\n",
       "      <td>0.9685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.097736</td>\n",
       "      <td>0.97310</td>\n",
       "      <td>0.114525</td>\n",
       "      <td>0.9686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.97352</td>\n",
       "      <td>0.113239</td>\n",
       "      <td>0.9679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.093888</td>\n",
       "      <td>0.97430</td>\n",
       "      <td>0.112773</td>\n",
       "      <td>0.9689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.092140</td>\n",
       "      <td>0.97462</td>\n",
       "      <td>0.110833</td>\n",
       "      <td>0.9686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.090376</td>\n",
       "      <td>0.97490</td>\n",
       "      <td>0.109390</td>\n",
       "      <td>0.9692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.088447</td>\n",
       "      <td>0.97582</td>\n",
       "      <td>0.108232</td>\n",
       "      <td>0.9694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.086821</td>\n",
       "      <td>0.97636</td>\n",
       "      <td>0.107983</td>\n",
       "      <td>0.9696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.97694</td>\n",
       "      <td>0.106863</td>\n",
       "      <td>0.9710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   1.296894   0.68712  0.622329        0.8577\n",
       "1   0.531448   0.86466  0.404510        0.8950\n",
       "2   0.407123   0.88862  0.342073        0.9071\n",
       "3   0.356107   0.89976  0.308893        0.9138\n",
       "4   0.325468   0.90738  0.287899        0.9179\n",
       "5   0.303295   0.91312  0.271276        0.9221\n",
       "6   0.285544   0.91846  0.258674        0.9255\n",
       "7   0.270923   0.92200  0.247235        0.9286\n",
       "8   0.258086   0.92612  0.237501        0.9313\n",
       "9   0.246588   0.92972  0.228514        0.9347\n",
       "10  0.236188   0.93234  0.220730        0.9368\n",
       "11  0.226811   0.93464  0.212489        0.9404\n",
       "12  0.218379   0.93790  0.205123        0.9425\n",
       "13  0.209956   0.94028  0.198972        0.9449\n",
       "14  0.202850   0.94254  0.193416        0.9460\n",
       "15  0.196117   0.94448  0.187653        0.9482\n",
       "16  0.189577   0.94626  0.181679        0.9502\n",
       "17  0.183490   0.94768  0.177308        0.9519\n",
       "18  0.177738   0.94966  0.172592        0.9527\n",
       "19  0.172505   0.95104  0.167937        0.9530\n",
       "20  0.167527   0.95226  0.166517        0.9549\n",
       "21  0.162628   0.95370  0.161386        0.9554\n",
       "22  0.157945   0.95482  0.157584        0.9562\n",
       "23  0.153663   0.95614  0.155496        0.9564\n",
       "24  0.149584   0.95742  0.150942        0.9584\n",
       "25  0.145546   0.95746  0.147726        0.9586\n",
       "26  0.141769   0.95912  0.144666        0.9603\n",
       "27  0.138136   0.96042  0.143015        0.9609\n",
       "28  0.134638   0.96124  0.140093        0.9610\n",
       "29  0.131455   0.96256  0.138251        0.9616\n",
       "30  0.128167   0.96322  0.136347        0.9639\n",
       "31  0.125103   0.96446  0.133106        0.9624\n",
       "32  0.122073   0.96526  0.131148        0.9627\n",
       "33  0.119511   0.96626  0.128756        0.9645\n",
       "34  0.116679   0.96712  0.127323        0.9651\n",
       "35  0.113897   0.96754  0.125836        0.9650\n",
       "36  0.111369   0.96888  0.123596        0.9660\n",
       "37  0.108823   0.96924  0.121646        0.9663\n",
       "38  0.106625   0.97020  0.120240        0.9670\n",
       "39  0.104363   0.97118  0.118080        0.9670\n",
       "40  0.102167   0.97192  0.118093        0.9674\n",
       "41  0.099954   0.97216  0.115532        0.9685\n",
       "42  0.097736   0.97310  0.114525        0.9686\n",
       "43  0.095901   0.97352  0.113239        0.9679\n",
       "44  0.093888   0.97430  0.112773        0.9689\n",
       "45  0.092140   0.97462  0.110833        0.9686\n",
       "46  0.090376   0.97490  0.109390        0.9692\n",
       "47  0.088447   0.97582  0.108232        0.9694\n",
       "48  0.086821   0.97636  0.107983        0.9696\n",
       "49  0.085106   0.97694  0.106863        0.9710"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0858 - accuracy: 0.9735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08582097291946411, 0.9735000133514404]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.003, 0.   , 0.   , 0.   , 0.997, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude   \n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88  \\\n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target, random_state=42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En regresión siempre sale una neurona porque realmente devuelve un solo número"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7918 - val_loss: 2.5791\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4691 - val_loss: 3.0055\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4885 - val_loss: 9.0525\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4926 - val_loss: 2.9159\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4380 - val_loss: 2.9276\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4203 - val_loss: 0.3947\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4023 - val_loss: 0.3618\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3888 - val_loss: 0.3602\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3844 - val_loss: 0.3700\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3780 - val_loss: 0.3627\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3754 - val_loss: 0.3710\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3772 - val_loss: 0.3649\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.3778\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3693 - val_loss: 0.3706\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3653 - val_loss: 0.3412\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3622 - val_loss: 0.3942\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3608 - val_loss: 0.3391\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3696 - val_loss: 0.3558\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3736 - val_loss: 0.3541\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3634 - val_loss: 0.3522\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1) # Si no se pone es relu, viene por defecto\n",
    "]) # No usamos un Flaten porque no es una matriz, el flaten solo se usa cuando hay matrices que suelen ser imagenes\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\") #al compilar se le mete la función de pérdida y el optimizador\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3527\n",
      "0.35268041491508484\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5719953],\n",
       "       [1.4945469],\n",
       "       [4.083253 ],\n",
       "       [2.5133455],\n",
       "       [2.9286652]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4106307054913964\n",
      "0.8551872146103914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(mean_squared_error(y_test[:5], y_pred))\n",
    "print(r2_score(y_test[:5], y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo  \n",
    "  \n",
    "Con pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# with open(\"model.pk1\", \"rb\") as m:\n",
    "#     pickle.dump(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"models/mocel.pk1\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"models/model.pk1\", \"rb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3521\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3497\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3485\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3465\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3451\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3440\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3422A: 0s - los\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3408\n",
      "Epoch 9/30\n",
      "219/363 [=================>............] - ETA: 0s - loss: 0.3336"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MIGUEL~1\\AppData\\Local\\Temp/ipykernel_6572/577377571.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                    \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                    callbacks = [checkpoint_cb])\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1208\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1209\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[0;32m   1210\u001b[0m                 \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1248\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m       \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m       can_run_full_execution = (\n\u001b[0;32m   1252\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    647\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    718\u001b[0m     \"\"\"\n\u001b[0;32m    719\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[1;34m()\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[1;32m--> 690\u001b[1;33m           self.handle, self._dtype)\n\u001b[0m\u001b[0;32m    691\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m--> 470\u001b[1;33m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[0m\u001b[0;32m    471\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\") # Aqui se dice en que archivo quieres que se guarde. Tiene un argumento que es save_freq que determina cada cuantos epochs quiere que se guarde, también hay un argumento que es save_best_only\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb]) # aqui en callbacks se determina el modelcheckpoint que has puesto antes para que se guarde el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3553 - val_loss: 0.4011\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3583 - val_loss: 0.3707\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3520 - val_loss: 0.4386\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4914 - val_loss: 0.3951\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3594 - val_loss: 0.4792\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3541 - val_loss: 0.3655\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3501 - val_loss: 0.5304\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3493 - val_loss: 0.7576\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3504 - val_loss: 1.1242\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3520 - val_loss: 0.3286\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3437 - val_loss: 0.3436\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3437 - val_loss: 0.3513\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3487 - val_loss: 0.3440\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3776 - val_loss: 0.3447\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3443 - val_loss: 0.3344\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5) # la paciencia determina el número de epoch que espera que no mejore para parar, tambien tiene el min_delta, mirar en documentación\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=20,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
